{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load zplsc_c_echogram.py\n",
    "\"\"\"\n",
    "@package mi.dataset.driver.zplsc_c\n",
    "@file mi/dataset/driver/zplsc_c/zplsc_c_echogram.py\n",
    "@author Craig Risien/Rene Gelinas\n",
    "@brief ZPLSC Echogram generation for the ooicore\n",
    "\n",
    "Release notes:\n",
    "\n",
    "This class supports the generation of ZPLSC-C echograms.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import mi.dataset.driver.zplsc_c.zplsc_functions as zf\n",
    "\n",
    "__author__ = 'Rene Gelinas'\n",
    "\n",
    "\n",
    "class ZplscCParameters(object):\n",
    "    # TODO: This class should be replaced by methods to get the CCs from the system.\n",
    "    # Configuration Parameters\n",
    "    Salinity = 32   # Salinity in psu\n",
    "    Pressure = 150  # in dbars (~ depth of instrument in meters).\n",
    "    Bins2Avg = 1    # number of range bins to average - 1 is no averaging\n",
    "\n",
    "\n",
    "class ZplscCCalibrationCoefficients(object):\n",
    "    # TODO: This class should be replaced by methods to get the CCs from the system.\n",
    "    ka = 464.3636\n",
    "    kb = 3000.0\n",
    "    kc = 1.893\n",
    "    A = 0.001466\n",
    "    B = 0.0002388\n",
    "    C = 0.000000100335\n",
    "\n",
    "    TVR = []\n",
    "    VTX = []\n",
    "    BP = []\n",
    "    EL = []\n",
    "    DS = []\n",
    "\n",
    "    # Freq 38kHz\n",
    "    TVR.append(1.691999969482e2)\n",
    "    VTX.append(1.533999938965e2)\n",
    "    BP.append(8.609999902546e-3)\n",
    "    EL.append(1.623000030518e2)\n",
    "    DS.append(2.280000038445e-2)\n",
    "\n",
    "    # Freq 125kHz\n",
    "    TVR.append(1.668999938965e2)\n",
    "    VTX.append(5.8e+01)\n",
    "    BP.append(1.530999969691e-2)\n",
    "    EL.append(1.376999969482e2)\n",
    "    DS.append(2.280000038445e-2)\n",
    "\n",
    "    # Freq 200kHz\n",
    "    TVR.append(1.688999938965e2)\n",
    "    VTX.append(9.619999694824e1)\n",
    "    BP.append(1.530999969691e-2)\n",
    "    EL.append(1.456000061035e2)\n",
    "    DS.append(2.250000089407e-2)\n",
    "\n",
    "    # Freq 455kHz\n",
    "    TVR.append(1.696000061035e2)\n",
    "    VTX.append(1.301000061035e2)\n",
    "    BP.append(8.609999902546e-3)\n",
    "    EL.append(1.491999969482e2)\n",
    "    DS.append(2.300000004470e-2)\n",
    "\n",
    "\n",
    "class ZPLSCCEchogram(object):\n",
    "    def __init__(self):\n",
    "        self.cc = ZplscCCalibrationCoefficients()\n",
    "        self.params = ZplscCParameters()\n",
    "\n",
    "    def compute_backscatter(self, profile_hdr, chan_data, sound_speed, depth_range, sea_absorb):\n",
    "        \"\"\"\n",
    "        Compute the backscatter volumes values for one zplsc_c profile data record.\n",
    "        This code was borrowed from ASL MatLab code that reads in zplsc-c raw data\n",
    "        and performs calculations in order to compute the backscatter volume in db.\n",
    "\n",
    "        :param profile_hdr: Raw profile header with metadata from the zplsc-c instrument.\n",
    "        :param chan_data: Raw frequency data from the zplsc-c instrument.\n",
    "        :param sound_speed: Speed of sound at based on speed of sound, pressure and salinity.\n",
    "        :param depth_range: Range of the depth of the measurements\n",
    "        :param sea_absorb: Seawater absorption coefficient for each frequency\n",
    "        :return: sv: Volume backscatter in db\n",
    "        \"\"\"\n",
    "\n",
    "        __N = []\n",
    "        if self.params.Bins2Avg > 1:\n",
    "            for chan in range(profile_hdr.num_channels):\n",
    "                el = self.cc.EL[chan] - 2.5/self.cc.DS[chan] + np.array(chan_data[chan])/(26214*self.cc.DS[chan])\n",
    "                power = 10**(el/10)\n",
    "\n",
    "                # Perform bin averaging\n",
    "                num_bins = len(chan_data[chan])/self.params.Bins2Avg\n",
    "                pwr_avg = []\n",
    "                for _bin in range(num_bins):\n",
    "                    pwr_avg.append(np.mean(power[_bin*self.params.Bins2Avg:(_bin+1)*self.params.Bins2Avg]))\n",
    "\n",
    "                el_avg = 10*np.log10(pwr_avg)\n",
    "                __N.append(np.round(26214*self.cc.DS[chan]*(el_avg - self.cc.EL[chan] + 2.5/self.cc.DS[chan])))\n",
    "\n",
    "        else:\n",
    "            for chan in range(profile_hdr.num_channels):\n",
    "                __N.append(np.array(chan_data[chan]))\n",
    "\n",
    "        sv = []\n",
    "        for chan in range(profile_hdr.num_channels):\n",
    "            # Calculate correction to Sv due to non square transmit pulse\n",
    "            sv_offset = zf.compute_sv_offset(profile_hdr.frequency[chan], profile_hdr.pulse_length[chan])\n",
    "            sv.append(self.cc.EL[chan]-2.5/self.cc.DS[chan] + __N[chan]/(26214*self.cc.DS[chan]) - self.cc.TVR[chan] -\n",
    "                      20*np.log10(self.cc.VTX[chan]) + 20*np.log10(depth_range[chan]) +\n",
    "                      2*sea_absorb[chan]*depth_range[chan] -\n",
    "                      10*np.log10(0.5*sound_speed*profile_hdr.pulse_length[chan]/1e6*self.cc.BP[chan]) +\n",
    "                      sv_offset)\n",
    "\n",
    "        return sv\n",
    "\n",
    "    def compute_echogram_metadata(self, profile_hdr):\n",
    "        \"\"\"\n",
    "        Compute the metadata parameters needed to compute the zplsc-c volume backscatter values.\n",
    "\n",
    "        :param  profile_hdr: Raw profile header with metadata from the zplsc-c instrument.\n",
    "        :return: sound_speed : Speed of sound based on temperature, pressure and salinity.\n",
    "                 depth_range : Range of depth values of the zplsc-c data.\n",
    "                 sea_absorb : Sea absorption based on temperature, pressure, salinity and frequency.\n",
    "        \"\"\"\n",
    "\n",
    "        # If the temperature sensor is available, compute the temperature from the counts.\n",
    "        temperature = 0\n",
    "        if profile_hdr.is_sensor_available:\n",
    "            temperature = zf.zplsc_c_temperature(profile_hdr.temperature, self.cc.ka, self.cc.kb, self.cc.kc,\n",
    "                                                 self.cc.A, self.cc.B, self.cc.C)\n",
    "\n",
    "        sound_speed = zf.zplsc_c_ss(temperature, self.params.Pressure, self.params.Salinity)\n",
    "\n",
    "        _m = []\n",
    "        depth_range = []\n",
    "        for chan in range(profile_hdr.num_channels):\n",
    "            _m.append(np.array([x for x in range(1, (profile_hdr.num_bins[chan]/self.params.Bins2Avg)+1)]))\n",
    "            depth_range.append(sound_speed*profile_hdr.lockout_index[0]/(2*profile_hdr.digitization_rate[0]) +\n",
    "                               (sound_speed/4)*(((2*_m[chan]-1)*profile_hdr.range_samples[0]*self.params.Bins2Avg-1) /\n",
    "                                                float(profile_hdr.digitization_rate[0]) +\n",
    "                                                profile_hdr.pulse_length[0]/1e6))\n",
    "\n",
    "        sea_absorb = []\n",
    "        for chan in range(profile_hdr.num_channels):\n",
    "            # Calculate absorption coefficient for each frequency.\n",
    "            sea_absorb.append(zf.zplsc_c_absorbtion(temperature, self.params.Pressure, self.params.Salinity,\n",
    "                                                    profile_hdr.frequency[chan]))\n",
    "\n",
    "        return sound_speed, depth_range, sea_absorb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from struct import unpack_from, unpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataParticleKey():\n",
    "    PKT_FORMAT_ID = \"pkt_format_id\"\n",
    "    PKT_VERSION = \"pkt_version\"\n",
    "    STREAM_NAME = \"stream_name\"\n",
    "    INTERNAL_TIMESTAMP = \"internal_timestamp\"\n",
    "    PORT_TIMESTAMP = \"port_timestamp\"\n",
    "    DRIVER_TIMESTAMP = \"driver_timestamp\"\n",
    "    PREFERRED_TIMESTAMP = \"preferred_timestamp\"\n",
    "    QUALITY_FLAG = \"quality_flag\"\n",
    "    VALUES = \"values\"\n",
    "    VALUE_ID = \"value_id\"\n",
    "    VALUE = \"value\"\n",
    "    BINARY = \"binary\"\n",
    "    NEW_SEQUENCE = \"new_sequence\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser(object):\n",
    "    \"\"\" abstract class to show API needed for plugin poller objects \"\"\"\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    def get_records(self, max_count):\n",
    "        \"\"\"\n",
    "        Returns a list of particles (following the instrument driver structure).\n",
    "        \"\"\"\n",
    "        raise NotImplementedException(\"get_records() not overridden!\")\n",
    "\n",
    "    def _publish_sample(self, samples):\n",
    "        \"\"\"\n",
    "        Publish the samples with the given publishing callback.\n",
    "        @param samples The list of data particle to publish up to the system\n",
    "        \"\"\"\n",
    "        if isinstance(samples, list):\n",
    "            self._publish_callback(samples)\n",
    "        else:\n",
    "            self._publish_callback([samples])\n",
    "\n",
    "    def _extract_sample(self, particle_class, regex, raw_data, port_timestamp=None, internal_timestamp=None,\n",
    "                        preferred_ts=DataParticleKey.INTERNAL_TIMESTAMP):\n",
    "        \"\"\"\n",
    "        Extract sample from a response line if present and publish\n",
    "        parsed particle\n",
    "\n",
    "        @param particle_class The class to instantiate for this specific\n",
    "            data particle. Parameterizing this allows for simple, standard\n",
    "            behavior from this routine\n",
    "        @param regex The regular expression that matches a data sample if regex\n",
    "                     is none then process every line\n",
    "        @param raw_data data to input into this particle.\n",
    "        @param port_timestamp the port_timestamp (default: None)\n",
    "        @param internal_timestamp the internal_timestamp (default: None)\n",
    "        @param preferred_ts the preferred timestamp (default: INTERNAL_TIMESTAMP)\n",
    "        @retval return a raw particle if a sample was found, else None\n",
    "        \"\"\"\n",
    "\n",
    "        particle = None\n",
    "\n",
    "        try:\n",
    "            if regex is None or regex.match(raw_data):\n",
    "                particle = particle_class(raw_data, port_timestamp=port_timestamp, internal_timestamp=internal_timestamp,\n",
    "                                          preferred_timestamp=preferred_ts)\n",
    "\n",
    "                # need to actually parse the particle fields to find out of there are errors\n",
    "                particle.generate_dict()\n",
    "                encoding_errors = particle.get_encoding_errors()\n",
    "                if encoding_errors:\n",
    "                    log.warn(\"Failed to encode: %s\", encoding_errors)\n",
    "                    raise SampleEncodingException(\"Failed to encode: %s\" % encoding_errors)\n",
    "\n",
    "        except (RecoverableSampleException, SampleEncodingException) as e:\n",
    "            log.error(\"Sample exception detected: %s raw data: %s\", e, raw_data)\n",
    "            if self._exception_callback:\n",
    "                self._exception_callback(e)\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "        return particle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleParser(Parser):\n",
    "\n",
    "    def __init__(self, config, stream_handle, exception_callback):\n",
    "        \"\"\"\n",
    "        Initialize the simple parser, which does not use state or the chunker\n",
    "        and sieve functions.\n",
    "        @param config: The parser configuration dictionary\n",
    "        @param stream_handle: The stream handle of the file to parse\n",
    "        @param exception_callback: The callback to use when an exception occurs\n",
    "        \"\"\"\n",
    "\n",
    "        # the record buffer which will store all parsed particles\n",
    "        self._record_buffer = []\n",
    "        # a flag indicating if the file has been parsed or not\n",
    "        self._file_parsed = False\n",
    "\n",
    "\n",
    "\n",
    "    def parse_file(self):\n",
    "        \"\"\"\n",
    "        This method must be overridden.  This method should open and read the file and parser the data within, and at\n",
    "        the end of this method self._record_buffer will be filled with all the particles in the file.\n",
    "        \"\"\"\n",
    "        raise NotImplementedException(\"parse_file() not overridden!\")\n",
    "\n",
    "    def get_records(self, number_requested=1):\n",
    "        \"\"\"\n",
    "        Initiate parsing the file if it has not been done already, and pop particles off the record buffer to\n",
    "        return as many as requested if they are available in the buffer.\n",
    "        @param number_requested the number of records requested to be returned\n",
    "        @return an array of particles, with a length of the number requested or less\n",
    "        \"\"\"\n",
    "        particles_to_return = []\n",
    "\n",
    "        if number_requested > 0:\n",
    "            if self._file_parsed is False:\n",
    "                self.parse_file()\n",
    "                self._file_parsed = True\n",
    "\n",
    "        while len(particles_to_return) < number_requested and len(self._record_buffer) > 0:\n",
    "            particles_to_return.append(self._record_buffer.pop(0))\n",
    "\n",
    "        return particles_to_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROFILE_DATA_DELIMITER = '\\xfd\\x02'  # Byte Offset 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZplscCParticleKey():\n",
    "    \"\"\"\n",
    "    Class that defines fields that need to be extracted for the data particle.\n",
    "    \"\"\"\n",
    "    TRANS_TIMESTAMP = \"zplsc_c_transmission_timestamp\"\n",
    "    SERIAL_NUMBER = \"serial_number\"\n",
    "    PHASE = \"zplsc_c_phase\"\n",
    "    BURST_NUMBER = \"burst_number\"\n",
    "    TILT_X = \"zplsc_c_tilt_x_counts\"\n",
    "    TILT_Y = \"zplsc_c_tilt_y_counts\"\n",
    "    BATTERY_VOLTAGE = \"zplsc_c_battery_voltage_counts\"\n",
    "    TEMPERATURE = \"zplsc_c_temperature_counts\"\n",
    "    PRESSURE = \"zplsc_c_pressure_counts\"\n",
    "    IS_AVERAGED_DATA = \"zplsc_c_is_averaged_data\"\n",
    "    FREQ_CHAN_1 = \"zplsc_frequency_channel_1\"\n",
    "    VALS_CHAN_1 = \"zplsc_values_channel_1\"\n",
    "    DEPTH_CHAN_1 = \"zplsc_depth_range_channel_1\"\n",
    "    FREQ_CHAN_2 = \"zplsc_frequency_channel_2\"\n",
    "    VALS_CHAN_2 = \"zplsc_values_channel_2\"\n",
    "    DEPTH_CHAN_2 = \"zplsc_depth_range_channel_2\"\n",
    "    FREQ_CHAN_3 = \"zplsc_frequency_channel_3\"\n",
    "    VALS_CHAN_3 = \"zplsc_values_channel_3\"\n",
    "    DEPTH_CHAN_3 = \"zplsc_depth_range_channel_3\"\n",
    "    FREQ_CHAN_4 = \"zplsc_frequency_channel_4\"\n",
    "    VALS_CHAN_4 = \"zplsc_values_channel_4\"\n",
    "    DEPTH_CHAN_4 = \"zplsc_depth_range_channel_4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AzfpProfileHeader():\n",
    "    _pack_ = 1                              # 124 bytes in the header (includes the 2 byte delimiter)\n",
    "    _fields_ = [                            # V Byte Offset (from delimiter)\n",
    "        ('burst_num', 'i2'),            # 002 - Burst number\n",
    "        ('serial_num', 'i2'),           # 004 - Instrument Serial number\n",
    "        ('ping_status', 'i2'),          # 006 - Ping Status\n",
    "        ('burst_interval', 'i2'),         # 008 - Burst Interval (seconds)\n",
    "        ('year', 'i2'),                 # 012 - Year\n",
    "        ('month', 'i2'),                # 014 - Month\n",
    "        ('day', 'i2'),                  # 016 - Day\n",
    "        ('hour', 'i2'),                 # 018 - Hour\n",
    "        ('minute', 'i2'),               # 020 - Minute\n",
    "        ('second', 'i2'),               # 022 - Second\n",
    "        ('hundredths', 'i2'),           # 024 - Hundreths of a second\n",
    "        ('digitization_rate', 'i2'*4),  # 026 - Digitization Rate (channels 1-4) (64000, 40000 or 20000)\n",
    "        ('lockout_index', 'i2'*4),      # 034 - The sample number of samples skipped at start of ping (channels 1-4)\n",
    "        ('num_bins', 'i2'*4),           # 042 - Number of bins (channels 1-4)\n",
    "        ('range_samples', 'i2'*4),      # 050 - Range samples per bin (channels 1-4)\n",
    "        ('num_pings_profile', 'i2'),    # 058 - Number of pings per profile\n",
    "        ('is_averaged_pings', 'i2'),    # 060 - Indicates if pings are averaged in time\n",
    "        ('num_pings_burst', 'i2'),      # 062 - Number of pings that have been acquired in this burst\n",
    "        ('ping_period', 'i2'),          # 064 - Ping period in seconds\n",
    "        ('first_ping', 'i2'),           # 066 - First ping number (if averaged, first averaged ping number)\n",
    "        ('second_ping', 'i2'),          # 068 - Last ping number (if averaged, last averaged ping number)\n",
    "        ('is_averaged_data', 'i2'*4),    # 070 - 1 = averaged data (5 bytes), 0 = not averaged (2 bytes)\n",
    "        ('error_num', 'i2'),            # 074 - Error number if an error occurred\n",
    "        ('phase', 'i2'),                 # 076 - Phase used to acquire this profile\n",
    "        ('is_overrun', 'i2'),            # 077 - 1 if an over run occurred\n",
    "        ('num_channels', 'i2'),          # 078 - Number of channels (1, 2, 3 or 4)\n",
    "        ('gain', 'i2'*4),                # 079 - Gain (channels 1-4) 0, 1, 2, 3 (Obsolete)\n",
    "        ('spare', 'i2'),                 # 083 - Spare\n",
    "        ('pulse_length', 'i2'*4),       # 084 - Pulse length (channels 1-4) (uS)\n",
    "        ('board_num', 'i2''i2'*4),          # 092 - Board number of the data (channels 1-4)\n",
    "        ('frequency', 'i2'*4),          # 100 - Board frequency (channels 1-4)\n",
    "        ('is_sensor_available', 'i2'),  # 108 - Indicate if pressure/temperature sensor is available\n",
    "        ('tilt_x', 'i2'),               # 110 - Tilt X (counts)\n",
    "        ('tilt_y', 'i2'),               # 112 - Tilt Y (counts)\n",
    "        ('battery_voltage', 'i2'),      # 114 - Battery voltage (counts)\n",
    "        ('pressure', 'i2'),             # 116 - Pressure (counts)\n",
    "        ('temperature', 'i2'),          # 118 - Temperature (counts)\n",
    "        ('ad_channel_6', 'i2'),         # 120 - AD channel 6\n",
    "        ('ad_channel_7', 'i2')          # 122 - AD channel 7\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_file_path(filepath, output_path=None):\n",
    "    # Extract the file time from the file name\n",
    "    absolute_path = os.path.abspath(filepath)\n",
    "    filename = os.path.basename(absolute_path).upper()\n",
    "    directory_name = os.path.dirname(absolute_path)\n",
    "\n",
    "    output_path = directory_name if output_path is None else output_path\n",
    "    image_file = filename.replace('.01A', '.png')\n",
    "    return os.path.join(output_path, image_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZplscCCalibrationCoefficients(object):\n",
    "    # TODO: This class should be replaced by methods to get the CCs from the system.\n",
    "    DS = list()\n",
    "\n",
    "    # Freq 38kHz\n",
    "    DS.append(2.280000038445e-2)\n",
    "\n",
    "    # Freq 125kHz\n",
    "    DS.append(2.280000038445e-2)\n",
    "\n",
    "    # Freq 200kHz\n",
    "    DS.append(2.250000089407e-2)\n",
    "\n",
    "    # Freq 455kHz\n",
    "    DS.append(2.300000004470e-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZplscCParser(SimpleParser):\n",
    "\n",
    "   \n",
    "    def find_next_record(self):\n",
    "        good_delimiter = True\n",
    "        delimiter = self._stream_handle.read(2)\n",
    "        while delimiter not in [PROFILE_DATA_DELIMITER, '']:\n",
    "            good_delimiter = False\n",
    "            delimiter = delimiter[1:2]\n",
    "            delimiter += self._stream_handle.read(1)\n",
    "\n",
    "        if not good_delimiter:\n",
    "            self._exception_callback('Invalid record delimiter found.\\n')\n",
    "\n",
    "    def parse_record(self):\n",
    "        \"\"\"\n",
    "        Parse one profile data record of the zplsc-c data file.\n",
    "        \"\"\"\n",
    "        chan_values = [[], [], [], []]\n",
    "        overflow_values = [[], [], [], []]\n",
    "\n",
    "        # Parse the data values portion of the record.\n",
    "        for chan in range(self.ph.num_channels):\n",
    "            num_bins = self.ph.num_bins[chan]\n",
    "\n",
    "            # Set the data structure format for the scientific data, based on whether\n",
    "            # the data is averaged or not. Construct the data structure and read the\n",
    "            # data bytes for the current channel. Unpack the data based on the structure.\n",
    "            if self.ph.is_averaged_data[chan]:\n",
    "                data_struct_format = '>' + str(num_bins) + 'I'\n",
    "            else:\n",
    "                data_struct_format = '>' + str(num_bins) + 'H'\n",
    "            data_struct = struct.Struct(data_struct_format)\n",
    "            data = self._stream_handle.read(data_struct.size)\n",
    "            chan_values[chan] = data_struct.unpack(data)\n",
    "\n",
    "            # If the data type is for averaged data, calculate the averaged data taking the\n",
    "            # the linear sum channel values and overflow values and using calculations from\n",
    "            # ASL MatLab code.\n",
    "            if self.ph.is_averaged_data[chan]:\n",
    "                overflow_struct_format = '>' + str(num_bins) + 'B'\n",
    "                overflow_struct = struct.Struct(overflow_struct_format)\n",
    "                overflow_data = self._stream_handle.read(num_bins)\n",
    "                overflow_values[chan] = overflow_struct.unpack(overflow_data)\n",
    "\n",
    "                if self.ph.is_averaged_pings:\n",
    "                    divisor = self.ph.num_pings_profile * self.ph.range_samples[chan]\n",
    "                else:\n",
    "                    divisor = self.ph.range_samples[chan]\n",
    "\n",
    "                linear_sum_values = np.array(chan_values[chan])\n",
    "                linear_overflow_values = np.array(overflow_values[chan])\n",
    "\n",
    "                values = (linear_sum_values + (linear_overflow_values * 0xFFFFFFFF))/divisor\n",
    "                values = (np.log10(values) - 2.5) * (8*0xFFFF) * self.cc.DS[chan]\n",
    "                values[np.isinf(values)] = 0\n",
    "                chan_values[chan] = values\n",
    "\n",
    "        # Convert the date and time parameters to a epoch time from 01-01-1900.\n",
    "        timestamp = (datetime(self.ph.year, self.ph.month, self.ph.day,\n",
    "                              self.ph.hour, self.ph.minute, self.ph.second,\n",
    "                              (self.ph.hundredths * 10000)) - datetime(1900, 1, 1)).total_seconds()\n",
    "\n",
    "        sound_speed, depth_range, sea_absorb = self.zplsc_echogram.compute_echogram_metadata(self.ph)\n",
    "\n",
    "        chan_values = self.zplsc_echogram.compute_backscatter(self.ph, chan_values, sound_speed, depth_range,\n",
    "                                                              sea_absorb)\n",
    "\n",
    "        zplsc_particle_data = {\n",
    "            ZplscCParticleKey.TRANS_TIMESTAMP: timestamp,\n",
    "            ZplscCParticleKey.SERIAL_NUMBER: str(self.ph.serial_num),\n",
    "            ZplscCParticleKey.PHASE: self.ph.phase,\n",
    "            ZplscCParticleKey.BURST_NUMBER: self.ph.burst_num,\n",
    "            ZplscCParticleKey.TILT_X: self.ph.tilt_x,\n",
    "            ZplscCParticleKey.TILT_Y: self.ph.tilt_y,\n",
    "            ZplscCParticleKey.BATTERY_VOLTAGE: self.ph.battery_voltage,\n",
    "            ZplscCParticleKey.PRESSURE: self.ph.pressure,\n",
    "            ZplscCParticleKey.TEMPERATURE: self.ph.temperature,\n",
    "            ZplscCParticleKey.IS_AVERAGED_DATA: list(self.ph.is_averaged_data),\n",
    "            ZplscCParticleKey.FREQ_CHAN_1: float(self.ph.frequency[0]),\n",
    "            ZplscCParticleKey.VALS_CHAN_1: list(chan_values[0]),\n",
    "            ZplscCParticleKey.DEPTH_CHAN_1: list(depth_range[0]),\n",
    "            ZplscCParticleKey.FREQ_CHAN_2: float(self.ph.frequency[1]),\n",
    "            ZplscCParticleKey.VALS_CHAN_2: list(chan_values[1]),\n",
    "            ZplscCParticleKey.DEPTH_CHAN_2: list(depth_range[1]),\n",
    "            ZplscCParticleKey.FREQ_CHAN_3: float(self.ph.frequency[2]),\n",
    "            ZplscCParticleKey.VALS_CHAN_3: list(chan_values[2]),\n",
    "            ZplscCParticleKey.DEPTH_CHAN_3: list(depth_range[2]),\n",
    "            ZplscCParticleKey.FREQ_CHAN_4: float(self.ph.frequency[3]),\n",
    "            ZplscCParticleKey.VALS_CHAN_4: list(chan_values[3]),\n",
    "            ZplscCParticleKey.DEPTH_CHAN_4: list(depth_range[3])\n",
    "        }\n",
    "\n",
    "        return zplsc_particle_data, timestamp, chan_values, depth_range\n",
    "\n",
    "    def parse_file(self):\n",
    "        self.ph = AzfpProfileHeader()\n",
    "        self.find_next_record()\n",
    "        while self._stream_handle.readinto(self.ph):\n",
    "            try:\n",
    "                # Parse the current record\n",
    "                zplsc_particle_data, timestamp, _, _ = self.parse_record()\n",
    "\n",
    "                # Create the data particle\n",
    "                particle = self._extract_sample(ZplscCRecoveredDataParticle, None, zplsc_particle_data, timestamp,\n",
    "                                                timestamp, DataParticleKey.PORT_TIMESTAMP)\n",
    "                if particle is not None:\n",
    "                    log.trace('Parsed particle: %s' % particle.generate_dict())\n",
    "                    self._record_buffer.append(particle)\n",
    "\n",
    "            except (IOError, OSError) as ex:\n",
    "                self._exception_callback('Reading stream handle: %s: %s\\n' % (self._stream_handle.name, ex.message))\n",
    "                return\n",
    "            except struct.error as ex:\n",
    "                self._exception_callback('Unpacking the data from the data structure: %s' % ex.message)\n",
    "            except exceptions.ValueError as ex:\n",
    "                self._exception_callback('Transition timestamp has invalid format: %s' % ex.message)\n",
    "            except (SampleException, RecoverableSampleException) as ex:\n",
    "                self._exception_callback('Creating data particle: %s' % ex.message)\n",
    "\n",
    "            # Clear the profile header data structure and find the next record.\n",
    "            self.ph = AzfpProfileHeader()\n",
    "            self.find_next_record()\n",
    "\n",
    "    def create_echogram(self, echogram_file_path=None):\n",
    "        \"\"\"\n",
    "        Parse the *.O1A zplsc_c data file and create the echogram from this data.\n",
    "        :param echogram_file_path: Path to store the echogram locally.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        import logging\n",
    "        sv_dict = {}\n",
    "        data_times = []\n",
    "        frequencies = {}\n",
    "        depth_range = []\n",
    "\n",
    "        input_file_path =None#self._stream_handle.name\n",
    "        logging.info('Begin processing echogram data: %r', input_file_path)\n",
    "        image_path = generate_image_file_path(input_file_path, echogram_file_path)\n",
    "\n",
    "        self.ph = AzfpProfileHeader()\n",
    "        self.find_next_record()\n",
    "        while self._stream_handle.readinto(self.ph):\n",
    "            try:\n",
    "                _, timestamp, chan_data, depth_range = self.parse_record()\n",
    "\n",
    "                if not sv_dict:\n",
    "                    range_chan_data = range(1, len(chan_data)+1)\n",
    "                    sv_dict = {channel: [] for channel in range_chan_data}\n",
    "                    frequencies = {channel: float(self.ph.frequency[channel-1]) for channel in range_chan_data}\n",
    "\n",
    "                for channel in sv_dict:\n",
    "                    sv_dict[channel].append(chan_data[channel-1])\n",
    "\n",
    "                data_times.append(timestamp)\n",
    "\n",
    "            except (IOError, OSError) as ex:\n",
    "                self._exception_callback(ex)\n",
    "                return\n",
    "            except struct.error as ex:\n",
    "                self._exception_callback(ex)\n",
    "            except exceptions.ValueError as ex:\n",
    "                self._exception_callback(ex)\n",
    "            except (SampleException, RecoverableSampleException) as ex:\n",
    "                self._exception_callback(ex)\n",
    "\n",
    "            # Clear the profile header data structure and find the next record.\n",
    "            self.ph = AzfpProfileHeader()\n",
    "            self.find_next_record()\n",
    "\n",
    "        log.info('Completed processing all data: %r', input_file_path)\n",
    "\n",
    "        data_times = np.array(data_times)\n",
    "\n",
    "        for channel in sv_dict:\n",
    "            sv_dict[channel] = np.array(sv_dict[channel])\n",
    "\n",
    "        logging.info('Begin generating echogram: %r', image_path)\n",
    "\n",
    "        plot = ZPLSPlot(data_times, sv_dict, frequencies, depth_range[0][-1], depth_range[0][0])\n",
    "        plot.generate_plots()\n",
    "        plot.write_image(image_path)\n",
    "\n",
    "        log.info('Completed generating echogram: %r', image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleDataHandler(object):\n",
    "    def __init__(self):particle_data_handler\n",
    "    def addParticleSample(self, sample_type, sample):\n",
    "        log.debug(\"Sample type: %s, Sample data: %s\", sample_type, sample)\n",
    "        self._samples.setdefault(sample_type, []).append(sample)\n",
    "\n",
    "    def setParticleDataCaptureFailure(self):\n",
    "        log.debug(\"Particle data capture failed\")\n",
    "        self._failure = True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_exception_callback(exception):\n",
    "        \"\"\"\n",
    "        Callback function to log exceptions and continue.\n",
    "\n",
    "        @param exception - Exception that occurred\n",
    "        \"\"\"\n",
    "\n",
    "        log.info(\"Exception occurred: %s\", exception.message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSetDriverConfigKeys():\n",
    "    PARTICLE_MODULE = \"particle_module\"\n",
    "    PARTICLE_CLASS = \"particle_class\"\n",
    "    PARTICLE_CLASSES_DICT = \"particle_classes_dict\"\n",
    "    DIRECTORY = \"directory\"\n",
    "    STORAGE_DIRECTORY = \"storage_directory\"\n",
    "    PATTERN = \"pattern\"\n",
    "    FREQUENCY = \"frequency\"\n",
    "    FILE_MOD_WAIT_TIME = \"file_mod_wait_time\"\n",
    "    HARVESTER = \"harvester\"\n",
    "    PARSER = \"parser\"\n",
    "    MODULE = \"module\"\n",
    "    CLASS = \"class\"\n",
    "    URI = \"uri\"\n",
    "    CLASS_ARGS = \"class_args\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ZplscCParser' object has no attribute '_stream_handle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-84ff581ee51a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mzplsc_echogram_file_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:\\Oceanhackweek\\proyecto\\AFZP_matlab'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZplscCParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_file_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mrec_exception_callback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_echogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzplsc_echogram_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-47-929013a0bb2f>\u001b[0m in \u001b[0;36mcreate_echogram\u001b[1;34m(self, echogram_file_path)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAzfpProfileHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_next_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream_handle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-929013a0bb2f>\u001b[0m in \u001b[0;36mfind_next_record\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_next_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mgood_delimiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mdelimiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream_handle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mPROFILE_DATA_DELIMITER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mgood_delimiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ZplscCParser' object has no attribute '_stream_handle'"
     ]
    }
   ],
   "source": [
    "input_file_path = '18030100.01A'\n",
    "zplsc_echogram_file_path = 'C:\\Oceanhackweek\\proyecto\\AFZP_matlab'\n",
    "parser = ZplscCParser(None, open(input_file_path) , rec_exception_callback)\n",
    "parser.create_echogram(zplsc_echogram_file_path) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sv_offset(frequency, pulse_length):\n",
    "    \"\"\"\n",
    "    A correction must be made to compensate for the effects of the finite response\n",
    "    times of both the receiving and transmitting parts of the instrument. The magnitude\n",
    "    of the correction will depend on the length of the transmitted pulse, and the response\n",
    "    time (on both transmission and reception) of the instrument.\n",
    "\n",
    "    :param frequency: Frequency in KHz\n",
    "    :param pulse_length: Pulse length in uSecs\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    sv_offset = 0\n",
    "\n",
    "    if frequency > 38:  # 125,200,455,769 kHz\n",
    "        if pulse_length == 300:\n",
    "            sv_offset = 1.1\n",
    "        elif pulse_length == 500:\n",
    "            sv_offset = 0.8\n",
    "        elif pulse_length == 700:\n",
    "            sv_offset = 0.5\n",
    "        elif pulse_length == 900:\n",
    "            sv_offset = 0.3\n",
    "        elif pulse_length == 1000:\n",
    "            sv_offset = 0.3\n",
    "    else:  # 38 kHz\n",
    "        if pulse_length == 500:\n",
    "            sv_offset = 1.1\n",
    "        elif pulse_length == 1000:\n",
    "            sv_offset = 0.7\n",
    "\n",
    "    return sv_offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de fichero  C:\\Oceanhackweek\\proyecto\\AFZP_matlab\\mi_instrument\\mi\\dataset\\driver\\zplsc_c\\zplsc_functions.py\n",
    "decompress_power = np.array(power) * 10. * np.log10(2) / 256.\n",
    "vin = 2.5 * (counts / 65535)\n",
    "r = (ka + kb*vin) / (kc - vin)\n",
    "temperature = 1 / (a + b * (np.log(r)) + c * (np.log(r)**3)) - 273\n",
    "tilt = a + (b * counts) + (c * counts**2) + (d * counts**3)\n",
    "z = t/10\n",
    "sea_c = 1449.05 + (z * (45.7 + z*((-5.21) + 0.23*z))) + ((1.333 + z*((-0.126) + z*0.009)) * (s-35.0)) + \\(p/1000)*(16.3+0.18*(p/1000))\n",
    "# Calculate relaxation frequencies\n",
    "t_k = t + 273.0\n",
    "f1 = 1320.0*t_k * np.exp(-1700/t_k)\n",
    "f2 = 1.55e7*t_k * np.exp(-3052/t_k)\n",
    "\n",
    "# Coefficients for absorption equations\n",
    "k = 1 + p/10.0\n",
    "a = 8.95e-8 * (1 + t*(2.29e-2 - 5.08e-4*t))\n",
    "b = (s/35.0)*4.88e-7*(1+0.0134*t)*(1-0.00103*k + 3.7e-7*(k*k))\n",
    "c = 4.86e-13*(1+t*((-0.042)+t*(8.53e-4-t*6.23e-6)))*(1+k*(-3.84e-4+k*7.57e-8))\n",
    "freqk = freq*1000\n",
    "sea_abs = (a*f1*(freqk**2))/((f1*f1)+(freqk**2))+(b*f2*(freqk**2))/((f2*f2)+(freqk**2))+c*(freqk**2)\n",
    "\n",
    "#aplicar compute_sv_offset(frequency, pulse_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(power_data_dict[38000.0],aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(power_data_dict[120000.0],aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
